{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "import pandas\n",
    "\n",
    "dataset = pandas.read_csv(\"./AmesHousing.csv\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "#impute missing values in numeric categories with the median\n",
    "numeric_columns = dataset.select_dtypes(include='number').columns\n",
    "imputerNum = SimpleImputer(strategy=\"median\")\n",
    "dataset[numeric_columns] = imputerNum.fit_transform(dataset[numeric_columns])\n",
    "\n",
    "# Impute missing categorical values to \"NA\"\n",
    "categorical_columns = dataset.select_dtypes(include='object').columns\n",
    "imputerCat = SimpleImputer(strategy='constant', fill_value='NA')\n",
    "dataset[categorical_columns] = imputerCat.fit_transform(dataset[categorical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ordinalMapping = {\n",
    "\t\"NA\": -1,\n",
    "\t\"Po\": 0,\n",
    "\t\"Fa\": 1,\n",
    "\t\"TA\": 2,\n",
    "\t\"Gd\": 3,\n",
    "\t\"Ex\": 4\n",
    "}\n",
    "\n",
    "hotEncoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Ordering the orderable features and nulling the unorderable ones\n",
    "categories = {}\n",
    "for column in dataset.columns:\n",
    "\tcolumnData = dataset[column]\n",
    "\tif columnData.dtype == 'object':\n",
    "\t\tif columnData.apply(lambda item: item in ordinalMapping).all():\n",
    "\t\t\tprint(dataset[column].name)\n",
    "\t\t\tdataset[column] = columnData.apply(lambda item: ordinalMapping[item])\n",
    "\t\telse:\n",
    "\t\t\tnewData = hotEncoder.fit_transform(dataset[[column]])\n",
    "\t\t\tnewColumns = pandas.DataFrame(newData, columns=hotEncoder.get_feature_names_out([column]))\n",
    "\t\t\tdataset = pandas.concat([dataset, newColumns], axis=1).drop(column, axis=1)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding correlations between the variables\n",
    "By setting up a correlation table and printing it, we can find which values are good candidates for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the correlation between the different columns and the sales price\n",
    "correlation = dataset.corr();\n",
    "print(correlation[\"SalePrice\"].sort_values(ascending=False).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plot\n",
    "saleprice = dataset[\"SalePrice\"]\n",
    "plots = [\n",
    "\t\"Overall Qual\",\n",
    "\t\"Gr Liv Area\",\n",
    "\t\"Garage Area\",\n",
    "\t\"Total Bsmt SF\",\n",
    "\t\"Year Built\",\n",
    "\t\"Year Remod/Add\",\n",
    "\t\"Garage Yr Blt\",\n",
    "\t\"Mas Vnr Area\"\n",
    "]\n",
    "\n",
    "for i in plots:\n",
    "\tplot.scatter(dataset[i], saleprice)\n",
    "\tplot.title(i)\n",
    "\tplot.show()\n",
    "\tplot.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "This is where we perform linear regression on the data. For this, we use the \"Gross Living Area\" feature in order to predict the sale price. Although \"Overall Quality\" has a higher correlation with sale price, we chose to use Gross Living Area because of how the value, despite being numerical, is an ordinal categorical value between 0 and 10. This does not necessarily make it a bad fit for the data, but it makes it less precise for regression (due to data attempting to fit only specific intervals, rather than using a continuous stream of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Setting up the values for regression\n",
    "quality_plot = np.array(dataset[\"Gr Liv Area\"]).reshape(-1, 1)\n",
    "sale_price_plot = np.array(dataset[\"SalePrice\"]).reshape(-1, 1)\n",
    "\n",
    "# Splitting into training and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(quality_plot, sale_price_plot, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"{len(x_train)} train instances + {len(x_test)} test instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "# Performing linear regression\n",
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(x_train, y_train)\n",
    "\n",
    "# Predicting the y-test results\n",
    "y_predicted = linear_regression.predict(x_test)\n",
    "\n",
    "# Plotting the test data agains the predicted test result\n",
    "plot.scatter(x_test, y_test)\n",
    "plot.plot(x_test, y_predicted, \"-r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_predicted = linear_regression.predict(x_test)\n",
    "lin_mse = mean_squared_error(y_test, y_predicted)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print(f\"Root Mean Square Error: {lin_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Regression\n",
    "For polynomial regression, the \"Year Built\" feature seems to have a strangely exponential impact on the price. Therefore we have chosen to investigate that correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "x_axis = \"Year Built\"\n",
    "linear_regression = LinearRegression()\n",
    "\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "x_poly = poly.fit_transform(dataset[[x_axis]])\n",
    "y_axis = dataset[\"SalePrice\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_poly, y_axis, test_size=0.2, random_state=42)\n",
    "linear_regression.fit(x_train, y_train)\n",
    "\n",
    "y_pred = linear_regression.predict(x_test)\n",
    "\n",
    "plot.scatter(x_test[:,1], y_test)\n",
    "plot.scatter(x_test[:,1], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_mse = mean_squared_error(y_test, y_pred)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print(f\"Root Mean Square Error: {lin_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
